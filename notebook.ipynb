{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IT Ticket Classifier — DHAUZ Challenge\n",
        "\n",
        "Notebook executável: carrega o dataset, amostra 200 tickets, monta o RAG (embeddings + FAISS), executa o fluxo LangGraph em exemplos e na amostra, calcula métricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path(\".\").resolve()\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(ROOT / \".env\")\n",
        "\n",
        "import config\n",
        "np.random.seed(config.SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Baixar dataset do Kaggle (só se ainda não tiver o CSV em data/raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset em: /Users/moises/Documents/ticket-classifier:/data/raw/all_tickets_processed_improved_v3.csv\n"
          ]
        }
      ],
      "source": [
        "from src.prep import download_from_kaggle\n",
        "\n",
        "path = download_from_kaggle()\n",
        "print(f\"Dataset em: {path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Carregar dataset, amostrar 200 tickets e montar o vector store (RAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afc35decf4a7401d85965af8d0f08fca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector store carregado de: /Users/moises/Documents/ticket-classifier:/outputs/artifacts\n",
            "Classes: ['Access', 'Administrative rights', 'HR Support', 'Hardware', 'Internal Project', 'Miscellaneous', 'Purchase', 'Storage']\n",
            "Amostra: 200 tickets\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from src.prep import load_dataset, get_text_and_label_columns, stratified_sample\n",
        "from src.rag import VectorStore\n",
        "\n",
        "def make_ticket_text(row, text_cols):\n",
        "    parts = [str(row.get(c, \"\")) for c in text_cols if c in row.index]\n",
        "    return \" \".join(p for p in parts if p and str(p).strip())\n",
        "\n",
        "df = load_dataset()\n",
        "text_cols, label_col = get_text_and_label_columns(df)\n",
        "n_sample = min(config.SAMPLE_SIZE, len(df))\n",
        "df_sample = stratified_sample(df, label_col, n=n_sample)\n",
        "df_sample.to_csv(config.DATA_PROCESSED / \"sample_200.csv\", index=False)\n",
        "\n",
        "texts = [make_ticket_text(row, text_cols) for _, row in df_sample.iterrows()]\n",
        "labels = df_sample[label_col].astype(str).tolist()\n",
        "classes = sorted(set(labels))\n",
        "\n",
        "artifact_path = config.ARTIFACTS_DIR\n",
        "if (artifact_path / \"index.faiss\").exists():\n",
        "    store = VectorStore.load(artifact_path)\n",
        "    print(\"Vector store carregado de:\", artifact_path)\n",
        "else:\n",
        "    vc = VectorStore()\n",
        "    store = vc.build(texts, labels)\n",
        "    store.save(artifact_path)\n",
        "    print(\"Vector store construído e salvo em:\", artifact_path)\n",
        "print(\"Classes:\", classes)\n",
        "print(\"Amostra:\", len(df_sample), \"tickets\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuição por classe:\n",
            "Topic_group\n",
            "Hardware                 25\n",
            "Access                   25\n",
            "Miscellaneous            25\n",
            "HR Support               25\n",
            "Purchase                 25\n",
            "Administrative rights    25\n",
            "Storage                  25\n",
            "Internal Project         25\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Distribuição por classe:\")\n",
        "print(df_sample[label_col].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Inferência em exemplos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e2ef8bed79d412ba697a1749628eb3e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "{\"event\": \"llm_usage\", \"source\": \"knn\", \"model\": \"n/a\", \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"requests\": 0, \"confidence\": 0.8}\n",
            "{\"event\": \"llm_usage\", \"source\": \"knn\", \"model\": \"n/a\", \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"requests\": 0, \"confidence\": 0.8}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Ticket 1 ---\n",
            "Texto (trecho): monitor request vulcan friday october pm hello please log each user monitor allocation user vulcan thank weekend engineer friday october vulcan parte  ...\n",
            "Saída: {'classe': 'Purchase', 'justificativa': 'Classe atribuída: Purchase. Termos do ticket: monitor request vulcan friday october pm hello please log each user monitor allocation user vulcan thank weekend engineer friday october vulcan parte ne va respective va.'}\n",
            "\n",
            "--- Ticket 2 ---\n",
            "Texto (trecho): stopped when docker start was executed sent wednesday february hi we having same problem we had few days ago server was stopped when executed docker s ...\n",
            "Saída: {'classe': 'Hardware', 'justificativa': 'Classe atribuída: Hardware. Termos do ticket: stopped when docker start was executed sent wednesday february hi we having same problem we had few days ago server was stopped when executed docker start looks like if machine....'}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{\"event\": \"llm_usage\", \"source\": \"classification\", \"model\": \"nvidia/nemotron-3-nano-30b-a3b:free\", \"input_tokens\": 175, \"output_tokens\": 50, \"total_tokens\": 225, \"requests\": 1}\n",
            "{\"event\": \"llm_usage\", \"source\": \"justification\", \"model\": \"nvidia/nemotron-3-nano-30b-a3b:free\", \"input_tokens\": 421, \"output_tokens\": 146, \"total_tokens\": 567, \"requests\": 1}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Ticket 3 ---\n",
            "Texto (trecho): issue re access through for hello still work attached log error received during installation restarted machine disconnected tethered phone can connect ...\n",
            "Saída: {'classe': 'Access', 'justificativa': \"O ticket menciona 'issue re access through', 'can connect' e problemas de 'disconnected tethered phone', indicando dificuldades de acesso à rede ou ao serviço.\"}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# store, classes e texts já carregados na célula 1.\n",
        "from src.graph import build_pipeline, run_pipeline\n",
        "\n",
        "compiled, _, _, _ = build_pipeline(store, classes)\n",
        "\n",
        "for i in range(min(3, len(texts))):\n",
        "    out = run_pipeline(compiled, texts[i], classes)\n",
        "    print(f\"--- Ticket {i+1} ---\")\n",
        "    print(\"Texto (trecho):\", texts[i][:150], \"...\")\n",
        "    print(\"Saída:\", out)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Rodar na amostra de 200 e salvar resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{\"event\": \"llm_usage\", \"source\": \"justification\", \"model\": \"nvidia/nemotron-3-nano-30b-a3b:free\", \"input_tokens\": 433, \"output_tokens\": 140, \"total_tokens\": 573, \"requests\": 1}\n",
            "{\"event\": \"llm_usage\", \"source\": \"classification\", \"model\": \"nvidia/nemotron-3-nano-30b-a3b:free\", \"input_tokens\": 175, \"output_tokens\": 50, \"total_tokens\": 225, \"requests\": 1}\n",
            "{\"event\": \"llm_usage\", \"source\": \"classification\", \"model\": \"nvidia/nemotron-3-nano-30b-a3b:free\", \"input_tokens\": 228, \"output_tokens\": 50, \"total_tokens\": 278, \"requests\": 1}\n",
            "{\"event\": \"llm_usage\", \"source\": \"classification\", \"model\": \"nvidia/nemotron-3-nano-30b-a3b:free\", \"input_tokens\": 356, \"output_tokens\": 50, \"total_tokens\": 406, \"requests\": 1}\n",
            "{\"event\": \"llm_usage\", \"source\": \"justification\", \"model\": \"nvidia/nemotron-3-nano-30b-a3b:free\", \"input_tokens\": 569, \"output_tokens\": 128, \"total_tokens\": 697, \"requests\": 1}\n",
            "{\"event\": \"llm_usage\", \"source\": \"classification\", \"model\": \"nvidia/nemotron-3-nano-30b-a3b:free\", \"input_tokens\": 214, \"output_tokens\": 50, \"total_tokens\": 264, \"requests\": 1}\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 706, in _completions_create\n",
            "    return await self.client.chat.completions.create(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2676, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/openai/_base_client.py\", line 1884, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/openai/_base_client.py\", line 1669, in request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-min. ', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '16', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1771702440000'}, 'provider_name': None}}, 'user_id': 'user_2l5BY045tbcIe1oVJCAaQz8FMhv'}\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/moises/Documents/ticket-classifier:/src/justification/generator.py\", line 125, in generate_justification_text\n",
            "    result = agent.run_sync(\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 386, in run_sync\n",
            "    return _utils.get_event_loop().run_until_complete(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
            "    return f.result()\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/asyncio/futures.py\", line 202, in result\n",
            "    raise self._exception.with_traceback(self._exception_tb)\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 259, in run\n",
            "    async with self.iter(\n",
            "               ^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/contextlib.py\", line 231, in __aexit__\n",
            "    await self.gen.athrow(value)\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/pydantic_ai/agent/__init__.py\", line 722, in iter\n",
            "    graph.iter(\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/contextlib.py\", line 231, in __aexit__\n",
            "    await self.gen.athrow(value)\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/pydantic_graph/beta/graph.py\", line 270, in iter\n",
            "    async with GraphRun[StateT, DepsT, OutputT](\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/pydantic_graph/beta/graph.py\", line 423, in __aexit__\n",
            "    await self._async_exit_stack.__aexit__(exc_type, exc_val, exc_tb)\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/contextlib.py\", line 754, in __aexit__\n",
            "    raise exc_details[1]\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/contextlib.py\", line 735, in __aexit__\n",
            "    cb_suppress = cb(*exc_details)\n",
            "                  ^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
            "    self.gen.throw(value)\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/pydantic_graph/beta/graph.py\", line 981, in _unwrap_exception_groups\n",
            "    raise exception\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/pydantic_graph/beta/graph.py\", line 750, in _run_tracked_task\n",
            "    result = await self._run_task(t_)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/pydantic_graph/beta/graph.py\", line 782, in _run_task\n",
            "    output = await node.call(step_context)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/pydantic_graph/beta/step.py\", line 253, in _call_node\n",
            "    return await node.run(GraphRunContext(state=ctx.state, deps=ctx.deps))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 456, in run\n",
            "    return await self._make_request(ctx)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 501, in _make_request\n",
            "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 619, in request\n",
            "    response = await self._completions_create(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 741, in _completions_create\n",
            "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
            "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: nvidia/nemotron-3-nano-30b-a3b:free, body: {'message': 'Rate limit exceeded: free-models-per-min. ', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '16', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1771702440000'}, 'provider_name': None}}\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3701, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/var/folders/qc/40cp3vzn26dgkntppc0jv9tc0000gn/T/ipykernel_78866/459808454.py\", line 10, in <module>\n",
            "    out = run_pipeline(compiled, text, classes)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/Documents/ticket-classifier:/src/graph/pipeline.py\", line 130, in run_pipeline\n",
            "    final = compiled.invoke(initial, run_config)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/langgraph/pregel/main.py\", line 3071, in invoke\n",
            "    for chunk in self.stream(\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/langgraph/pregel/main.py\", line 2646, in stream\n",
            "    for _ in runner.tick(\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/langgraph/pregel/_runner.py\", line 167, in tick\n",
            "    run_with_retry(\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
            "    return task.proc.invoke(task.input, config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/langgraph/_internal/_runnable.py\", line 656, in invoke\n",
            "    input = context.run(step.invoke, input, config, **kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/langgraph/_internal/_runnable.py\", line 400, in invoke\n",
            "    ret = self.func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/Documents/ticket-classifier:/src/graph/pipeline.py\", line 104, in <lambda>\n",
            "    lambda s: _justify(s, vector_store, k=config.KNN_K),\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/Documents/ticket-classifier:/src/graph/pipeline.py\", line 66, in _justify\n",
            "    justificativa = generate_justification_text(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/moises/Documents/ticket-classifier:/src/justification/generator.py\", line 152, in generate_justification_text\n",
            "    time.sleep(wait)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "from src.logging_utils import log_result\n",
        "\n",
        "results_path = config.OUTPUTS / \"results_sample.jsonl\"\n",
        "if results_path.exists():\n",
        "    results_path.unlink()\n",
        "\n",
        "predictions = []\n",
        "for i, row in df_sample.iterrows():\n",
        "    text = make_ticket_text(row, text_cols)\n",
        "    out = run_pipeline(compiled, text, classes)\n",
        "    pred = out[\"classe\"]\n",
        "    predictions.append(pred)\n",
        "    log_result({\"ticket_index\": int(i), \"true\": row[label_col], \"pred\": pred, \"justificativa\": out[\"justificativa\"]})\n",
        "\n",
        "print(f\"Salvos {len(predictions)} resultados em {results_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Métricas e relatório"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.metrics import compute_metrics, save_metrics_report\n",
        "\n",
        "y_true = df_sample[label_col].astype(str).tolist()\n",
        "metrics = compute_metrics(y_true, predictions, labels=classes)\n",
        "save_metrics_report(metrics)\n",
        "\n",
        "print(\"Accuracy:\", metrics[\"accuracy\"])\n",
        "print(\"F1 macro:\", metrics[\"f1_macro\"])\n",
        "print(\"F1 weighted:\", metrics[\"f1_weighted\"])\n",
        "print(\"\\nClassification report:\")\n",
        "for k, v in metrics[\"classification_report\"].items():\n",
        "    if isinstance(v, dict):\n",
        "        print(k, v)\n",
        "    else:\n",
        "        print(k, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Exemplo de saída JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "ex = run_pipeline(compiled, texts[0], classes)\n",
        "print(json.dumps(ex, indent=2, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "ex = run_pipeline(compiled, texts[0], classes)\n",
        "print(json.dumps(ex, indent=2, ensure_ascii=False))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ticket-classifier",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
