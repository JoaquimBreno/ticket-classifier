{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IT Ticket Classifier — DHAUZ Challenge\n",
        "\n",
        "Notebook executável: carrega o dataset, amostra 200 tickets, monta o RAG (embeddings + FAISS), executa o fluxo LangGraph em exemplos e na amostra, calcula métricas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path(\".\").resolve()\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(ROOT / \".env\")\n",
        "\n",
        "import config\n",
        "np.random.seed(config.SEED)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Baixar dataset do Kaggle (só se ainda não tiver o CSV em data/raw)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from src.prep import download_from_kaggle\n",
        "\n",
        "path = download_from_kaggle()\n",
        "print(f\"Dataset em: {path}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset em: /Users/moises/Documents/ticket-classifier:/data/raw/all_tickets_processed_improved_v3.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset completo → vector store; sample_200 → test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from src.prep import document_text, load_dataset, get_text_and_label_columns, stratified_sample\n",
        "from src.rag import VectorStore\n",
        "\n",
        "df_full = load_dataset()\n",
        "text_cols, label_col = get_text_and_label_columns(df_full)\n",
        "classes = sorted(set(df_full[label_col].astype(str)))\n",
        "\n",
        "n_sample = min(config.SAMPLE_SIZE, len(df_full))\n",
        "df_sample = stratified_sample(df_full, label_col, n=n_sample)\n",
        "df_sample.to_csv(config.DATA_PROCESSED / \"sample_200.csv\", index=False)\n",
        "ids_test = set(df_sample[\"id\"])\n",
        "df_train = df_full[~df_full[\"id\"].isin(ids_test)]\n",
        "\n",
        "texts_train = [document_text(row, text_cols) for _, row in df_train.iterrows()]\n",
        "labels_train = df_train[label_col].astype(str).tolist()\n",
        "ids_train = df_train[\"id\"].tolist()\n",
        "\n",
        "artifact_path = config.ARTIFACTS_DIR\n",
        "if (artifact_path / \"index.faiss\").exists():\n",
        "    store = VectorStore.load(artifact_path)\n",
        "    print(\"Vector store carregado de:\", artifact_path)\n",
        "else:\n",
        "    vc = VectorStore()\n",
        "    store = vc.build(texts_train, labels_train, ids=ids_train)\n",
        "    store.save(artifact_path)\n",
        "    print(\"Vector store construído (apenas train) e salvo em:\", artifact_path)\n",
        "\n",
        "texts = [document_text(row, text_cols) for _, row in df_sample.iterrows()]\n",
        "\n",
        "print(\"Classes:\", classes)\n",
        "print(\"Vector store (train): %d documentos\" % len(df_train))\n",
        "print(\"Test set (sample_200): %d tickets\" % len(df_sample))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30868edc6fe54f83a2ee8e3a2a2e0baf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ]
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Vector store carregado de: /Users/moises/Documents/ticket-classifier:/outputs/artifacts\n",
            "Classes: ['Access', 'Administrative rights', 'HR Support', 'Hardware', 'Internal Project', 'Miscellaneous', 'Purchase', 'Storage']\n",
            "Vector store (train): 47637 documentos\n",
            "Test set (sample_200): 200 tickets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Distribuição por classe:\")\n",
        "print(df_sample[label_col].value_counts())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distribuição por classe:\n",
            "Topic_group\n",
            "Hardware                 25\n",
            "Access                   25\n",
            "Miscellaneous            25\n",
            "HR Support               25\n",
            "Purchase                 25\n",
            "Administrative rights    25\n",
            "Storage                  25\n",
            "Internal Project         25\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Inferência em exemplos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# store, classes e texts já carregados na célula 1.\n",
        "import logging\n",
        "from tqdm.auto import tqdm\n",
        "from src.graph import build_pipeline, run_pipeline\n",
        "\n",
        "logging.getLogger(\"ticket_classifier.llm_usage\").setLevel(logging.WARNING)\n",
        "\n",
        "compiled, _, _, _ = build_pipeline(store, classes)\n",
        "\n",
        "for i in tqdm(range(min(3, len(texts))), desc=\"Exemplos\"):\n",
        "    out = run_pipeline(compiled, texts[i], classes)\n",
        "    print(f\"--- Ticket {i+1} ---\")\n",
        "    print(\"Texto (trecho):\", texts[i][:150], \"...\")\n",
        "    print(\"Saída:\", out)\n",
        "    print()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d55ff21e64a340638e95de1d3e7231a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Exemplos:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9b534bc716f4094b4c797805e2d1b30",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ]
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "{\"event\": \"classification\", \"classifier\": \"knn\", \"classe\": \"Hardware\", \"confidence\": 1.0}\n",
            "llama_context: n_ctx_per_seq (4096) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
            "ggml_metal_init: skipping kernel_set_rows_bf16                     (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_c4                (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h64       (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
            "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
            "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
            "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
            "{\"event\": \"justification\", \"model\": \"llama-local\", \"input_tokens\": 463, \"output_tokens\": 79, \"total_tokens\": 542}\n",
            "{\"event\": \"inference\", \"classification_source\": \"knn\", \"classe\": \"Hardware\", \"inference_time_sec\": 22.4027, \"justification_tokens\": 542}\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "--- Ticket 1 ---\n",
            "Texto (trecho): monitor request vulcan friday october pm hello please log each user monitor allocation user vulcan thank weekend engineer friday october vulcan parte  ...\n",
            "Saída: {'classe': 'Hardware', 'justificativa': 'O KNN foi favorável à classe Hardware pois os vizinhos mais próximos (6/6) também foram classificados como Hardware, com distâncias de 0.59 a 0.69. Essa alta confiança e semelhanças nos textos sustentam a classificação como problema relacionado a Hardware.', 'classification_source': 'knn', 'inference_time_sec': 22.402748082997277}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "{\"event\": \"classification\", \"classifier\": \"knn\", \"classe\": \"Hardware\", \"confidence\": 0.5714}\n",
            "{\"event\": \"classification\", \"classifier\": \"llm\", \"classe\": \"Hardware\", \"model\": \"llama-local\", \"input_tokens\": 384, \"output_tokens\": 9}\n",
            "{\"event\": \"justification\", \"model\": \"llama-local\", \"input_tokens\": 493, \"output_tokens\": 93, \"total_tokens\": 586}\n",
            "{\"event\": \"inference\", \"classification_source\": \"llm\", \"classe\": \"Hardware\", \"inference_time_sec\": 21.2903, \"classification_tokens\": 393, \"justification_tokens\": 586}\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "--- Ticket 2 ---\n",
            "Texto (trecho): stopped when docker start was executed sent wednesday february hi we having same problem we had few days ago server was stopped when executed docker s ...\n",
            "Saída: {'classe': 'Hardware', 'justificativa': 'O KNN foi favorável à classe Hardware porque os vizinhos mais próximos (distâncias 0.42, 0.74, 0.91 e 0.96) também foram classificados como Hardware, indicando que a similaridade entre os problemas é alta e que a causa provável é relacionada ao hardware, como problemas de instalação, acesso ou funcionamento do servidor.', 'classification_source': 'llm', 'inference_time_sec': 21.290285165945534}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "{\"event\": \"classification\", \"classifier\": \"knn\", \"classe\": \"Hardware\", \"confidence\": 1.0}\n",
            "{\"event\": \"justification\", \"model\": \"llama-local\", \"input_tokens\": 464, \"output_tokens\": 76, \"total_tokens\": 540}\n",
            "{\"event\": \"inference\", \"classification_source\": \"knn\", \"classe\": \"Hardware\", \"inference_time_sec\": 14.1442, \"classification_tokens\": 393, \"justification_tokens\": 540}\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "--- Ticket 3 ---\n",
            "Texto (trecho): issue re access through for hello still work attached log error received during installation restarted machine disconnected tethered phone can connect ...\n",
            "Saída: {'classe': 'Hardware', 'justificativa': 'O KNN foi favorável à classe Hardware pois todos os vizinhos mais próximos (distâncias entre 0,63 e 0,72) apresentam problemas de conexão relacionados a hardware, como instalação, autenticação e problemas de acesso, o que sustenta a classificação atribuída.', 'classification_source': 'knn', 'inference_time_sec': 14.144190667022485}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Rodar na amostra de 200 e salvar resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from src.logging_utils import log_result\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "results_path = config.OUTPUTS / \"results_sample.jsonl\"\n",
        "if results_path.exists():\n",
        "    results_path.unlink()\n",
        "\n",
        "predictions = []\n",
        "for pos, (_, row) in enumerate(tqdm(list(df_sample.iterrows()), desc=\"Pipeline\")):\n",
        "    text = document_text(row, text_cols)\n",
        "    out = run_pipeline(compiled, text, classes, thread_id=str(pos), instance_id=row[\"id\"])\n",
        "    pred = out[\"classe\"]\n",
        "    predictions.append(pred)\n",
        "    log_result({\n",
        "        \"id\": row[\"id\"],\n",
        "        \"ticket_index\": pos,\n",
        "        \"true\": row[label_col],\n",
        "        \"pred\": pred,\n",
        "        \"justificativa\": out[\"justificativa\"],\n",
        "        \"classification_source\": out.get(\"classification_source\"),\n",
        "        \"confidence\": out.get(\"confidence\"),\n",
        "        \"inference_time_sec\": out.get(\"inference_time_sec\"),\n",
        "    })\n",
        "\n",
        "print(f\"Salvos {len(predictions)} resultados em {results_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "827139ff50c749258d237bb87027456b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pipeline:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{\"event\": \"classification\", \"classifier\": \"knn\", \"classe\": \"Hardware\", \"confidence\": 1.0}\n",
            "{\"event\": \"justification\", \"model\": \"llama-local\", \"input_tokens\": 463, \"output_tokens\": 96, \"total_tokens\": 559}\n",
            "{\"event\": \"inference\", \"classification_source\": \"knn\", \"classe\": \"Hardware\", \"inference_time_sec\": 17.1582, \"justification_tokens\": 559}\n",
            "{\"event\": \"classification\", \"classifier\": \"knn\", \"classe\": \"Hardware\", \"confidence\": 0.5714}\n",
            "{\"event\": \"classification\", \"classifier\": \"llm\", \"classe\": \"Hardware\", \"model\": \"llama-local\", \"input_tokens\": 384, \"output_tokens\": 9}\n",
            "{\"event\": \"justification\", \"model\": \"llama-local\", \"input_tokens\": 493, \"output_tokens\": 75, \"total_tokens\": 568}\n",
            "{\"event\": \"inference\", \"classification_source\": \"llm\", \"classe\": \"Hardware\", \"inference_time_sec\": 22.8091, \"classification_tokens\": 393, \"justification_tokens\": 568}\n",
            "{\"event\": \"classification\", \"classifier\": \"knn\", \"classe\": \"Hardware\", \"confidence\": 1.0}\n",
            "{\"event\": \"justification\", \"model\": \"llama-local\", \"input_tokens\": 464, \"output_tokens\": 76, \"total_tokens\": 540}\n",
            "{\"event\": \"inference\", \"classification_source\": \"knn\", \"classe\": \"Hardware\", \"inference_time_sec\": 18.9104, \"justification_tokens\": 540}\n",
            "{\"event\": \"classification\", \"classifier\": \"knn\", \"classe\": \"Hardware\", \"confidence\": 1.0}\n",
            "{\"event\": \"justification\", \"model\": \"llama-local\", \"input_tokens\": 473, \"output_tokens\": 86, \"total_tokens\": 559}\n",
            "{\"event\": \"inference\", \"classification_source\": \"knn\", \"classe\": \"Hardware\", \"inference_time_sec\": 32.754, \"justification_tokens\": 559}\n",
            "{\"event\": \"classification\", \"classifier\": \"knn\", \"classe\": \"Hardware\", \"confidence\": 0.7143}\n",
            "{\"event\": \"classification\", \"classifier\": \"llm\", \"classe\": \"Hardware\", \"model\": \"llama-local\", \"input_tokens\": 506, \"output_tokens\": 9}\n",
            "{\"event\": \"justification\", \"model\": \"llama-local\", \"input_tokens\": 615, \"output_tokens\": 79, \"total_tokens\": 694}\n",
            "{\"event\": \"inference\", \"classification_source\": \"llm\", \"classe\": \"Hardware\", \"inference_time_sec\": 61.1353, \"classification_tokens\": 515, \"justification_tokens\": 694}\n",
            "{\"event\": \"classification\", \"classifier\": \"knn\", \"classe\": \"Hardware\", \"confidence\": 1.0}\n",
            "{\"event\": \"justification\", \"model\": \"llama-local\", \"input_tokens\": 498, \"output_tokens\": 74, \"total_tokens\": 572}\n",
            "{\"event\": \"inference\", \"classification_source\": \"knn\", \"classe\": \"Hardware\", \"inference_time_sec\": 29.8808, \"justification_tokens\": 572}\n",
            "{\"event\": \"classification\", \"classifier\": \"knn\", \"classe\": \"Hardware\", \"confidence\": 1.0}\n",
            "{\"event\": \"justification\", \"model\": \"llama-local\", \"input_tokens\": 494, \"output_tokens\": 84, \"total_tokens\": 578}\n",
            "{\"event\": \"inference\", \"classification_source\": \"knn\", \"classe\": \"Hardware\", \"inference_time_sec\": 28.6076, \"justification_tokens\": 578}\n",
            "{\"event\": \"classification\", \"classifier\": \"knn\", \"classe\": \"Hardware\", \"confidence\": 0.2857}\n",
            "{\"event\": \"classification\", \"classifier\": \"llm\", \"classe\": \"Purchase\", \"model\": \"llama-local\", \"input_tokens\": 388, \"output_tokens\": 9}\n",
            "{\"event\": \"justification\", \"model\": \"llama-local\", \"input_tokens\": 497, \"output_tokens\": 73, \"total_tokens\": 570}\n",
            "{\"event\": \"inference\", \"classification_source\": \"llm\", \"classe\": \"Purchase\", \"inference_time_sec\": 42.9748, \"classification_tokens\": 397, \"justification_tokens\": 570}\n",
            "{\"event\": \"classification\", \"classifier\": \"knn\", \"classe\": \"Hardware\", \"confidence\": 0.5714}\n",
            "{\"event\": \"classification\", \"classifier\": \"llm\", \"classe\": \"Miscellaneous\", \"model\": \"llama-local\", \"input_tokens\": 353, \"output_tokens\": 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Métricas e relatório"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from src.metrics import compute_metrics, save_metrics_report\n",
        "\n",
        "y_true = df_sample[label_col].astype(str).tolist()\n",
        "metrics = compute_metrics(y_true, predictions, labels=classes)\n",
        "save_metrics_report(metrics)\n",
        "\n",
        "print(\"Accuracy:\", metrics[\"accuracy\"])\n",
        "print(\"F1 macro:\", metrics[\"f1_macro\"])\n",
        "print(\"F1 weighted:\", metrics[\"f1_weighted\"])\n",
        "print(\"\\nClassification report:\")\n",
        "for k, v in metrics[\"classification_report\"].items():\n",
        "    if isinstance(v, dict):\n",
        "        print(k, v)\n",
        "    else:\n",
        "        print(k, v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Exemplo de saída JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "ex = run_pipeline(compiled, texts[0], classes)\n",
        "print(json.dumps(ex, indent=2, ensure_ascii=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "ex = run_pipeline(compiled, texts[0], classes)\n",
        "print(json.dumps(ex, indent=2, ensure_ascii=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ticket-classifier",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}