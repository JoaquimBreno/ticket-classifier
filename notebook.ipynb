{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IT Ticket Classifier — DHAUZ Challenge\n",
        "\n",
        "Notebook executável: carrega o dataset, amostra 200 tickets, monta o RAG (embeddings + FAISS), executa o fluxo LangGraph em exemplos e na amostra, calcula métricas.\n",
        "Arquitetura baseada em pesquisa com experimentação em \"labs/architecture-comparison.ipynb\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Resultados do labs (architecture-comparison)\n",
        "\n",
        "Gráfico de threshold KNN (cruzamento coverage × F1 macro) e tabela comparativa de modelos no conjunto de teste (hold-out excl. sample_200).\n",
        "\n",
        "![KNN: métricas vs confidence threshold](charts/threshold.png)\n",
        "Resultado mostra que threshold para maior coverage e maio f1 macro é 0.45\n",
        "Cruzamento (coverage ≈ F1 macro): threshold=0.45 → coverage=90.35%, F1 macro=0.8697, accuracy=0.8680\n",
        "Melhor equilíbrio (max coverage×F1): threshold=0.35 → coverage=95.31%, F1 macro=0.8450, accuracy=0.8424\n",
        "\n",
        "**Tabela comparativa (test set):**\n",
        "\n",
        "| model    | accuracy | f1_macro | f1_weighted |\n",
        "|----------|----------|----------|-------------|\n",
        "| RNN      | 0.772571 | 0.763023 | 0.773050    |\n",
        "| LSTM     | 0.800138 | 0.794236 | 0.801268    |\n",
        "| BiLSTM   | 0.831840 | 0.835082 | 0.832611    |\n",
        "| BiGRU    | 0.833218 | 0.838499 | 0.833300    |\n",
        "| CNN+BiGRU| 0.837354 | 0.842469 | 0.837848    |\n",
        "| KNN      | 0.833218 | 0.832331 | 0.832036    |\n",
        "\n",
        "### usaremos KNN pelo motivo de ser mais explicável e permitir construir uma base de conhecimento muito granular, veja mais em labs/architecture-comparison.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path(\".\").resolve()\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(ROOT / \".env\")\n",
        "\n",
        "import config\n",
        "np.random.seed(config.SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Baixar dataset do Kaggle (só se ainda não tiver o CSV em data/raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset em: /Users/moises/Documents/ticket-classifier/data/raw/all_tickets_processed_improved_v3.csv\n"
          ]
        }
      ],
      "source": [
        "from src.prep import download_from_kaggle\n",
        "\n",
        "path = download_from_kaggle()\n",
        "print(f\"Dataset em: {path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset completo → vector store; sample_200 → test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "683214422e2a45efb7dfaf7ca9311895",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector store carregado de: /Users/moises/Documents/ticket-classifier/outputs/artifacts\n",
            "Classes: ['Access', 'Administrative rights', 'HR Support', 'Hardware', 'Internal Project', 'Miscellaneous', 'Purchase', 'Storage']\n",
            "Vector store (train): 47637 documentos\n",
            "Test set (sample_200): 200 tickets\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from src.prep import document_text, load_dataset, get_text_and_label_columns, stratified_sample\n",
        "from src.rag import VectorStore\n",
        "\n",
        "df_full = load_dataset()\n",
        "text_cols, label_col = get_text_and_label_columns(df_full)\n",
        "classes = sorted(set(df_full[label_col].astype(str)))\n",
        "\n",
        "n_sample = min(config.SAMPLE_SIZE, len(df_full))\n",
        "df_sample = stratified_sample(df_full, label_col, n=n_sample)\n",
        "df_sample.to_csv(config.DATA_PROCESSED / \"sample_200.csv\", index=False)\n",
        "ids_test = set(df_sample[\"id\"])\n",
        "df_train = df_full[~df_full[\"id\"].isin(ids_test)]\n",
        "\n",
        "texts_train = [document_text(row, text_cols) for _, row in df_train.iterrows()]\n",
        "labels_train = df_train[label_col].astype(str).tolist()\n",
        "ids_train = df_train[\"id\"].tolist()\n",
        "\n",
        "artifact_path = config.ARTIFACTS_DIR\n",
        "if (artifact_path / \"index.faiss\").exists():\n",
        "    store = VectorStore.load(artifact_path)\n",
        "    print(\"Vector store carregado de:\", artifact_path)\n",
        "else:\n",
        "    vc = VectorStore()\n",
        "    store = vc.build(texts_train, labels_train, ids=ids_train)\n",
        "    store.save(artifact_path)\n",
        "    print(\"Vector store construído (apenas train) e salvo em:\", artifact_path)\n",
        "\n",
        "texts = [document_text(row, text_cols) for _, row in df_sample.iterrows()]\n",
        "\n",
        "print(\"Classes:\", classes)\n",
        "print(\"Vector store (train): %d documentos\" % len(df_train))\n",
        "print(\"Test set (sample_200): %d tickets\" % len(df_sample))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuição por classe:\n",
            "Topic_group\n",
            "Hardware                 25\n",
            "Access                   25\n",
            "Miscellaneous            25\n",
            "HR Support               25\n",
            "Purchase                 25\n",
            "Administrative rights    25\n",
            "Storage                  25\n",
            "Internal Project         25\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Distribuição por classe:\")\n",
        "print(df_sample[label_col].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Inferência em exemplos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d8bd93e14dc40cabeecbb32719b4291",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Exemplos:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "403e7a5b7f324049a46f304387cb3f18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "{\"step\": \"knn_classify\", \"event\": \"classification\", \"classe\": \"Hardware\", \"confidence\": 1.0}\n",
            "llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
            "ggml_metal_init: skipping kernel_set_rows_bf16                     (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_c4                (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h64       (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
            "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
            "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
            "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
            "{\"step\": \"agent_justify\", \"event\": \"justification\", \"input_tokens\": 401, \"output_tokens\": 85, \"total_tokens\": 486}\n",
            "{\"step\": \"inference\", \"event\": \"inference\", \"classification_source\": \"knn\", \"classe\": \"Hardware\", \"inference_time_sec\": 20.4661, \"justification_tokens\": 486}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Ticket 1 ---\n",
            "Texto (trecho): monitor request vulcan friday october pm hello please log each user monitor allocation user vulcan thank weekend engineer friday october vulcan parte  ...\n",
            "Saída: {'classe': 'Hardware', 'justificativa': \"Os termos 'monitor', 'vulcan', 'request', 'allocation' e 'log' correlacionam com a classe 'Hardware' pois mencionam a gestão de recursos de hardware. Além disso, os vizinhos KNN também mencionam 'monitor' e 'allocation', o que reforça a correlação com a classe 'Hardware'.\", 'classification_source': 'knn', 'confidence': 1.0, 'inference_time_sec': 20.46608570799981, 'classification_tokens': None, 'justification_tokens': 486}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{\"step\": \"knn_classify\", \"event\": \"classification\", \"classe\": \"Hardware\", \"confidence\": 0.5714}\n",
            "{\"step\": \"agent_justify\", \"event\": \"justification\", \"input_tokens\": 339, \"output_tokens\": 99, \"total_tokens\": 438}\n",
            "{\"step\": \"inference\", \"event\": \"inference\", \"classification_source\": \"knn\", \"classe\": \"Hardware\", \"inference_time_sec\": 14.0937, \"justification_tokens\": 438}\n",
            "{\"step\": \"knn_classify\", \"event\": \"classification\", \"classe\": \"Hardware\", \"confidence\": 1.0}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Ticket 2 ---\n",
            "Texto (trecho): stopped when docker start was executed sent wednesday february hi we having same problem we had few days ago server was stopped when executed docker s ...\n",
            "Saída: {'classe': 'Hardware', 'justificativa': \"O termo 'server stopped' é comum em todos os vizinhos e no próprio ticket, indicando que a classe atribuída 'Hardware' está relacionada a problemas de acesso ao servidor. Além disso, a menção a 'docker' e 'machine' nos vizinhos #0 e #3, e no próprio ticket, sugere que a classe está relacionada a problemas de execução de containers Docker.\", 'classification_source': 'knn', 'confidence': 0.5714285714285714, 'inference_time_sec': 14.093680292000045, 'classification_tokens': None, 'justification_tokens': 438}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{\"step\": \"agent_justify\", \"event\": \"justification\", \"input_tokens\": 402, \"output_tokens\": 121, \"total_tokens\": 523}\n",
            "{\"step\": \"inference\", \"event\": \"inference\", \"classification_source\": \"knn\", \"classe\": \"Hardware\", \"inference_time_sec\": 17.0763, \"justification_tokens\": 523}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Ticket 3 ---\n",
            "Texto (trecho): issue re access through for hello still work attached log error received during installation restarted machine disconnected tethered phone can connect ...\n",
            "Saída: {'classe': 'Hardware', 'justificativa': \"Os termos 're access through for hello still work attached log error received during installation restarted machine disconnected tethered phone can connect' correlacionam com a classe 'Hardware' pois mencionam problemas de conexão e instalação, que são comuns em problemas de hardware. Além disso, os vizinhos KNN (#0, #1, #2, #3, #4, #5 e #6) também mencionam problemas de conexão e instalação, o que reforça a classificação de 'Hardware'.\", 'classification_source': 'knn', 'confidence': 1.0, 'inference_time_sec': 17.07632058299987, 'classification_tokens': None, 'justification_tokens': 523}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# store, classes e texts já carregados na célula 1.\n",
        "import logging\n",
        "from tqdm.auto import tqdm\n",
        "from src.graph import build_pipeline, run_pipeline\n",
        "\n",
        "logging.getLogger(\"ticket_classifier.llm_usage\").setLevel(logging.WARNING)\n",
        "\n",
        "compiled, _, _ = build_pipeline(store)\n",
        "\n",
        "for i in tqdm(range(min(3, len(texts))), desc=\"Exemplos\"):\n",
        "    out = run_pipeline(compiled, texts[i], classes)\n",
        "    print(f\"--- Ticket {i+1} ---\")\n",
        "    print(\"Texto (trecho):\", texts[i][:150], \"...\")\n",
        "    print(\"Saída:\", out)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Rodar na amostra de 200 e salvar resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcbd56a555c146b083480386d792a48f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pipeline:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import logging\n",
        "import time\n",
        "from src.logging_utils import log_result\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "logging.getLogger(\"ticket_classifier.llm_usage\").setLevel(logging.WARNING)\n",
        "\n",
        "results_path = config.OUTPUTS / \"results_sample.jsonl\"\n",
        "if results_path.exists():\n",
        "    results_path.unlink()\n",
        "\n",
        "max_tickets = None\n",
        "it = list(df_sample.iterrows())\n",
        "if max_tickets is not None:\n",
        "    it = it[:max_tickets]\n",
        "\n",
        "predictions = []\n",
        "t0 = time.perf_counter()\n",
        "for pos, (_, row) in enumerate(tqdm(it, desc=\"Pipeline\")):\n",
        "    text = document_text(row, text_cols)\n",
        "    out = run_pipeline(compiled, text, classes, instance_id=row[\"id\"])\n",
        "    pred = out[\"classe\"]\n",
        "    predictions.append(pred)\n",
        "    log_result({\n",
        "        \"id\": row[\"id\"],\n",
        "        \"ticket_index\": pos,\n",
        "        \"true\": row[label_col],\n",
        "        \"pred\": pred,\n",
        "        \"justificativa\": out[\"justificativa\"],\n",
        "        \"classification_source\": out.get(\"classification_source\"),\n",
        "        \"confidence\": out.get(\"confidence\"),\n",
        "        \"inference_time_sec\": out.get(\"inference_time_sec\"),\n",
        "        \"classification_tokens\": out.get(\"classification_tokens\"),\n",
        "        \"justification_tokens\": out.get(\"justification_tokens\"),\n",
        "    })\n",
        "elapsed = time.perf_counter() - t0\n",
        "n = len(predictions)\n",
        "print(f\"Salvos {n} resultados em {results_path}\")\n",
        "print(f\"Tempo total: {elapsed:.1f}s | Média por ticket: {elapsed/n:.1f}s (gargalo: 1 chamada LLM por ticket)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Métricas e relatório"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.metrics import compute_metrics, save_metrics_report\n",
        "\n",
        "y_true = df_sample[label_col].astype(str).tolist()\n",
        "metrics = compute_metrics(y_true, predictions, labels=classes)\n",
        "save_metrics_report(metrics)\n",
        "\n",
        "print(\"Accuracy:\", metrics[\"accuracy\"])\n",
        "print(\"F1 macro:\", metrics[\"f1_macro\"])\n",
        "print(\"F1 weighted:\", metrics[\"f1_weighted\"])\n",
        "print(\"\\nClassification report:\")\n",
        "for k, v in metrics[\"classification_report\"].items():\n",
        "    if isinstance(v, dict):\n",
        "        print(k, v)\n",
        "    else:\n",
        "        print(k, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Exemplo de saída JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "ex = run_pipeline(compiled, texts[0], classes)\n",
        "print(json.dumps(ex, indent=2, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "ex = run_pipeline(compiled, texts[0], classes)\n",
        "print(json.dumps(ex, indent=2, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ticket-classifier",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
