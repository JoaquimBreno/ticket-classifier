{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IT Ticket Classifier — DHAUZ Challenge\n",
        "\n",
        "Notebook executável: carrega o dataset, amostra 200 tickets, monta o RAG (embeddings + FAISS), executa o fluxo LangGraph em exemplos e na amostra, calcula métricas.\n",
        "Arquitetura baseada em pesquisa com experimentação em \"labs/architecture-comparison.ipynb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path(\".\").resolve()\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(ROOT / \".env\")\n",
        "\n",
        "import config\n",
        "np.random.seed(config.SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Baixar dataset do Kaggle (só se ainda não tiver o CSV em data/raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset em: /Users/moises/Documents/ticket-classifier/data/raw/all_tickets_processed_improved_v3.csv\n"
          ]
        }
      ],
      "source": [
        "from src.prep import download_from_kaggle\n",
        "\n",
        "path = download_from_kaggle()\n",
        "print(f\"Dataset em: {path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset completo → vector store; sample_200 → test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7052189f5384b9f87f274bbd97d04da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector store carregado de: /Users/moises/Documents/ticket-classifier/outputs/artifacts\n",
            "Classes: ['Access', 'Administrative rights', 'HR Support', 'Hardware', 'Internal Project', 'Miscellaneous', 'Purchase', 'Storage']\n",
            "Vector store (train): 47637 documentos\n",
            "Test set (sample_200): 200 tickets\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from src.prep import document_text, load_dataset, get_text_and_label_columns, stratified_sample\n",
        "from src.rag import VectorStore\n",
        "\n",
        "df_full = load_dataset()\n",
        "text_cols, label_col = get_text_and_label_columns(df_full)\n",
        "classes = sorted(set(df_full[label_col].astype(str)))\n",
        "\n",
        "n_sample = min(config.SAMPLE_SIZE, len(df_full))\n",
        "df_sample = stratified_sample(df_full, label_col, n=n_sample)\n",
        "df_sample.to_csv(config.DATA_PROCESSED / \"sample_200.csv\", index=False)\n",
        "ids_test = set(df_sample[\"id\"])\n",
        "df_train = df_full[~df_full[\"id\"].isin(ids_test)]\n",
        "\n",
        "texts_train = [document_text(row, text_cols) for _, row in df_train.iterrows()]\n",
        "labels_train = df_train[label_col].astype(str).tolist()\n",
        "ids_train = df_train[\"id\"].tolist()\n",
        "\n",
        "artifact_path = config.ARTIFACTS_DIR\n",
        "if (artifact_path / \"index.faiss\").exists():\n",
        "    store = VectorStore.load(artifact_path)\n",
        "    print(\"Vector store carregado de:\", artifact_path)\n",
        "else:\n",
        "    vc = VectorStore()\n",
        "    store = vc.build(texts_train, labels_train, ids=ids_train)\n",
        "    store.save(artifact_path)\n",
        "    print(\"Vector store construído (apenas train) e salvo em:\", artifact_path)\n",
        "\n",
        "texts = [document_text(row, text_cols) for _, row in df_sample.iterrows()]\n",
        "\n",
        "print(\"Classes:\", classes)\n",
        "print(\"Vector store (train): %d documentos\" % len(df_train))\n",
        "print(\"Test set (sample_200): %d tickets\" % len(df_sample))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuição por classe:\n",
            "Topic_group\n",
            "Hardware                 25\n",
            "Access                   25\n",
            "Miscellaneous            25\n",
            "HR Support               25\n",
            "Purchase                 25\n",
            "Administrative rights    25\n",
            "Storage                  25\n",
            "Internal Project         25\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Distribuição por classe:\")\n",
        "print(df_sample[label_col].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Inferência em exemplos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9cfc4175d7e4065bb3bc1796b2dce95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Exemplos:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a27c7923ec454e37b265aaa66e55dd52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "llama_context: n_ctx_per_seq (4096) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
            "ggml_metal_init: skipping kernel_set_rows_bf16                     (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_c4                (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h64       (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
            "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
            "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
            "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Ticket 1 ---\n",
            "Texto (trecho): monitor request vulcan friday october pm hello please log each user monitor allocation user vulcan thank weekend engineer friday october vulcan parte  ...\n",
            "Saída: {'classe': 'Hardware', 'justificativa': \"Os vizinhos KNN sustentam a classe 'Hardware' porque todos os textos de ticket referem-se a problemas ou solicitações relacionados a equipamentos ou monitoramento, o que é típico de problemas de hardware.\", 'classification_source': 'knn', 'confidence': 1.0, 'inference_time_sec': 21.617789208015893, 'classification_tokens': None, 'justification_tokens': 416}\n",
            "\n",
            "--- Ticket 2 ---\n",
            "Texto (trecho): stopped when docker start was executed sent wednesday february hi we having same problem we had few days ago server was stopped when executed docker s ...\n",
            "Saída: {'classe': 'Hardware', 'justificativa': \"A confiança do KNN foi baixa devido à falta de características relevantes no texto para uma classificação precisa. O LLM, por outro lado, foi capaz de identificar a classe 'Hardware' com base nos seguintes trechos: 'server was stopped', 'docker start', 'machine have enough resources' e 'cannot access server', que sugerem problemas relacionados ao hardware.\", 'classification_source': 'llm', 'confidence': 0.0, 'inference_time_sec': 32.183071208011825, 'classification_tokens': 237, 'justification_tokens': 296}\n",
            "\n",
            "--- Ticket 3 ---\n",
            "Texto (trecho): issue re access through for hello still work attached log error received during installation restarted machine disconnected tethered phone can connect ...\n",
            "Saída: {'classe': 'Hardware', 'justificativa': \"Os vizinhos KNN sustentam a classe 'Hardware' porque todos os relatórios de problemas apresentados (desconexão, instalação, erro de log, etc.) estão relacionados a problemas de conexão e instalação, que são típicos de problemas de hardware.\", 'classification_source': 'knn', 'confidence': 1.0, 'inference_time_sec': 25.510207290994003, 'classification_tokens': 237, 'justification_tokens': 430}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# store, classes e texts já carregados na célula 1.\n",
        "import logging\n",
        "from tqdm.auto import tqdm\n",
        "from src.graph import build_pipeline, run_pipeline\n",
        "\n",
        "logging.getLogger(\"ticket_classifier.llm_usage\").setLevel(logging.WARNING)\n",
        "\n",
        "compiled, _, _, _ = build_pipeline(store, classes)\n",
        "\n",
        "for i in tqdm(range(min(3, len(texts))), desc=\"Exemplos\"):\n",
        "    out = run_pipeline(compiled, texts[i], classes)\n",
        "    print(f\"--- Ticket {i+1} ---\")\n",
        "    print(\"Texto (trecho):\", texts[i][:150], \"...\")\n",
        "    print(\"Saída:\", out)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Rodar na amostra de 200 e salvar resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "962d168d4b0548e8b2ae25e23d18f8a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pipeline:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pos, (_, row) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(\u001b[38;5;28mlist\u001b[39m(df_sample.iterrows()), desc=\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m     10\u001b[39m     text = document_text(row, text_cols)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     out = \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompiled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     pred = out[\u001b[33m\"\u001b[39m\u001b[33mclasse\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     13\u001b[39m     predictions.append(pred)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ticket-classifier/src/graph/pipeline.py:175\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m(compiled, ticket_text, classes, thread_id, instance_id)\u001b[39m\n\u001b[32m    173\u001b[39m     initial[\u001b[33m\"\u001b[39m\u001b[33minstance_id\u001b[39m\u001b[33m\"\u001b[39m] = instance_id\n\u001b[32m    174\u001b[39m t0 = time.perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m final = \u001b[43mcompiled\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m inference_time_sec = time.perf_counter() - t0\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(final, \u001b[38;5;28mdict\u001b[39m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/langgraph/pregel/main.py:3071\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3068\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3069\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3071\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3085\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/langgraph/pregel/main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ticket-classifier/src/graph/pipeline.py:146\u001b[39m, in \u001b[36mbuild_pipeline.<locals>.<lambda>\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m    142\u001b[39m builder.add_node(\u001b[33m\"\u001b[39m\u001b[33mknn_classify\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m s: _knn_classify(s, knn))\n\u001b[32m    143\u001b[39m builder.add_node(\u001b[33m\"\u001b[39m\u001b[33mllm_classify\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m s: _llm_classify(s, llm))\n\u001b[32m    144\u001b[39m builder.add_node(\n\u001b[32m    145\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgenerate_justification\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m s: \u001b[43m_justify\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mKNN_K\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    147\u001b[39m )\n\u001b[32m    148\u001b[39m builder.add_node(\u001b[33m\"\u001b[39m\u001b[33mlog_and_return\u001b[39m\u001b[33m\"\u001b[39m, _log_and_return)\n\u001b[32m    150\u001b[39m builder.set_entry_point(\u001b[33m\"\u001b[39m\u001b[33mpreprocess\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ticket-classifier/src/graph/pipeline.py:97\u001b[39m, in \u001b[36m_justify\u001b[39m\u001b[34m(state, vector_store, k)\u001b[39m\n\u001b[32m     91\u001b[39m         neighbors = vector_store.search(text, k=k) \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m     92\u001b[39m     winning_voters = [\n\u001b[32m     93\u001b[39m         (i, dist, (txt \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).strip()[:\u001b[32m200\u001b[39m])\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, (label, txt, dist) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(neighbors)\n\u001b[32m     95\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m label == classe\n\u001b[32m     96\u001b[39m     ]\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m justificativa, inp_tok, out_tok = \u001b[43magent_justify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mticket_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclasse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclasse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfidence\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwinning_voters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwinning_voters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mused_llm_for_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mused_llm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m log_justification(\n\u001b[32m    105\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mllama-local\u001b[39m\u001b[33m\"\u001b[39m, input_tokens=inp_tok, output_tokens=out_tok,\n\u001b[32m    106\u001b[39m     instance_id=state.get(\u001b[33m\"\u001b[39m\u001b[33minstance_id\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    107\u001b[39m )\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    109\u001b[39m     **state,\n\u001b[32m    110\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mjustificativa\u001b[39m\u001b[33m\"\u001b[39m: justificativa,\n\u001b[32m    111\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mjustification_tokens\u001b[39m\u001b[33m\"\u001b[39m: inp_tok + out_tok,\n\u001b[32m    112\u001b[39m }\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ticket-classifier/src/llm_local/agent.py:193\u001b[39m, in \u001b[36magent_justify\u001b[39m\u001b[34m(ticket_text, classe, confidence, winning_voters, used_llm_for_class)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m used_llm_for_class \u001b[38;5;129;01mand\u001b[39;00m winning_voters \u001b[38;5;129;01mand\u001b[39;00m confidence \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _justify_knn(backend, ticket_text, classe, confidence, winning_voters)\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_justify_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mticket_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfidence\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfidence\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ticket-classifier/src/llm_local/agent.py:163\u001b[39m, in \u001b[36m_justify_llm\u001b[39m\u001b[34m(backend, ticket_text, classe, confidence)\u001b[39m\n\u001b[32m    158\u001b[39m conf_str = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Confiança KNN (baixa): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfidence\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m confidence \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    159\u001b[39m user = (\n\u001b[32m    160\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTicket:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mticket_text[:config.JUSTIFICATION_MAX_CHARS]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mClasse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconf_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    161\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mJustifique: confiança baixa → LLM classificou; cite trechos do texto que indicaram a classe.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    162\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_justify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ticket-classifier/src/llm_local/agent.py:167\u001b[39m, in \u001b[36m_call_justify\u001b[39m\u001b[34m(backend, user, system)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_justify\u001b[39m(backend, user: \u001b[38;5;28mstr\u001b[39m, system: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     content, input_tokens, output_tokens = \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJUSTIFICATION_MAX_TOKENS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjson_object\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mschema\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mJustificationResponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_json_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m     justificativa = _parse_justification(content)\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m justificativa, input_tokens, output_tokens\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ticket-classifier/src/llm_local/backends/llama_cpp.py:74\u001b[39m, in \u001b[36mLlamaCppBackend.chat_completion\u001b[39m\u001b[34m(self, messages, max_tokens, temperature, response_format)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat_completion\u001b[39m(\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     67\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]],\n\u001b[32m   (...)\u001b[39m\u001b[32m     71\u001b[39m     response_format: \u001b[38;5;28mdict\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     72\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m     73\u001b[39m     llm = \u001b[38;5;28mself\u001b[39m._get_model()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     resp = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_chat_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     usage = resp.get(\u001b[33m\"\u001b[39m\u001b[33musage\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m     81\u001b[39m     content = (resp.get(\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m [{}])[\u001b[32m0\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m, {}).get(\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/llama_cpp/llama.py:2003\u001b[39m, in \u001b[36mLlama.create_chat_completion\u001b[39m\u001b[34m(self, messages, functions, function_call, tools, tool_choice, temperature, top_p, top_k, min_p, typical_p, stream, stop, seed, response_format, max_tokens, presence_penalty, frequency_penalty, repeat_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, logits_processor, grammar, logit_bias, logprobs, top_logprobs)\u001b[39m\n\u001b[32m   1965\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate a chat completion from a list of messages.\u001b[39;00m\n\u001b[32m   1966\u001b[39m \n\u001b[32m   1967\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1996\u001b[39m \u001b[33;03m    Generated chat completion or a stream of chat completion chunks.\u001b[39;00m\n\u001b[32m   1997\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1998\u001b[39m handler = (\n\u001b[32m   1999\u001b[39m     \u001b[38;5;28mself\u001b[39m.chat_handler\n\u001b[32m   2000\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._chat_handlers.get(\u001b[38;5;28mself\u001b[39m.chat_format)\n\u001b[32m   2001\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m llama_chat_format.get_chat_completion_handler(\u001b[38;5;28mself\u001b[39m.chat_format)\n\u001b[32m   2002\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2003\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllama\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2007\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2008\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2009\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2010\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2011\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2012\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2013\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2014\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2015\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2016\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2017\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2018\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2019\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2020\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2021\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2022\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2023\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2024\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2025\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2026\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2027\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2029\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2031\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2032\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2033\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/llama_cpp/llama_chat_format.py:669\u001b[39m, in \u001b[36mchat_formatter_to_chat_completion_handler.<locals>.chat_completion_handler\u001b[39m\u001b[34m(llama, messages, functions, function_call, tools, tool_choice, temperature, top_p, top_k, min_p, typical_p, stream, stop, seed, response_format, max_tokens, presence_penalty, frequency_penalty, repeat_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, logits_processor, grammar, logit_bias, logprobs, top_logprobs, **kwargs)\u001b[39m\n\u001b[32m    664\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(e), file=sys.stderr)\n\u001b[32m    665\u001b[39m         grammar = llama_grammar.LlamaGrammar.from_string(\n\u001b[32m    666\u001b[39m             llama_grammar.JSON_GBNF, verbose=llama.verbose\n\u001b[32m    667\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m completion_or_chunks = \u001b[43mllama\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    695\u001b[39m     tool_name = tool[\u001b[33m\"\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/llama_cpp/llama.py:1837\u001b[39m, in \u001b[36mLlama.create_completion\u001b[39m\u001b[34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[39m\n\u001b[32m   1835\u001b[39m     chunks: Iterator[CreateCompletionStreamResponse] = completion_or_chunks\n\u001b[32m   1836\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n\u001b[32m-> \u001b[39m\u001b[32m1837\u001b[39m completion: Completion = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcompletion_or_chunks\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   1838\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m completion\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/llama_cpp/llama.py:1322\u001b[39m, in \u001b[36mLlama._create_completion\u001b[39m\u001b[34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[39m\n\u001b[32m   1320\u001b[39m finish_reason = \u001b[33m\"\u001b[39m\u001b[33mlength\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1321\u001b[39m multibyte_fix = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1340\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mllama_cpp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mllama_token_is_eog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1341\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/llama_cpp/llama.py:914\u001b[39m, in \u001b[36mLlama.generate\u001b[39m\u001b[34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[39m\n\u001b[32m    912\u001b[39m \u001b[38;5;66;03m# Eval and sample\u001b[39;00m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    915\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m sample_idx < \u001b[38;5;28mself\u001b[39m.n_tokens:\n\u001b[32m    916\u001b[39m         token = \u001b[38;5;28mself\u001b[39m.sample(\n\u001b[32m    917\u001b[39m             top_k=top_k,\n\u001b[32m    918\u001b[39m             top_p=top_p,\n\u001b[32m   (...)\u001b[39m\u001b[32m    932\u001b[39m             idx=sample_idx,\n\u001b[32m    933\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/llama_cpp/llama.py:648\u001b[39m, in \u001b[36mLlama.eval\u001b[39m\u001b[34m(self, tokens)\u001b[39m\n\u001b[32m    644\u001b[39m n_tokens = \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[32m    645\u001b[39m \u001b[38;5;28mself\u001b[39m._batch.set_batch(\n\u001b[32m    646\u001b[39m     batch=batch, n_past=n_past, logits_all=\u001b[38;5;28mself\u001b[39m._logits_all\n\u001b[32m    647\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[38;5;66;03m# Save tokens\u001b[39;00m\n\u001b[32m    650\u001b[39m \u001b[38;5;28mself\u001b[39m.input_ids[n_past : n_past + n_tokens] = batch\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ticket-classifier/lib/python3.12/site-packages/llama_cpp/_internals.py:322\u001b[39m, in \u001b[36mLlamaContext.decode\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: LlamaBatch):\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     return_code = \u001b[43mllama_cpp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m return_code != \u001b[32m0\u001b[39m:\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mllama_decode returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from src.logging_utils import log_result\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "results_path = config.OUTPUTS / \"results_sample.jsonl\"\n",
        "if results_path.exists():\n",
        "    results_path.unlink()\n",
        "\n",
        "predictions = []\n",
        "for pos, (_, row) in enumerate(tqdm(list(df_sample.iterrows()), desc=\"Pipeline\")):\n",
        "    text = document_text(row, text_cols)\n",
        "    out = run_pipeline(compiled, text, classes, thread_id=str(pos), instance_id=row[\"id\"])\n",
        "    pred = out[\"classe\"]\n",
        "    predictions.append(pred)\n",
        "    log_result({\n",
        "        \"id\": row[\"id\"],\n",
        "        \"ticket_index\": pos,\n",
        "        \"true\": row[label_col],\n",
        "        \"pred\": pred,\n",
        "        \"justificativa\": out[\"justificativa\"],\n",
        "        \"classification_source\": out.get(\"classification_source\"),\n",
        "        \"confidence\": out.get(\"confidence\"),\n",
        "        \"inference_time_sec\": out.get(\"inference_time_sec\"),\n",
        "        \"classification_tokens\": out.get(\"classification_tokens\"),\n",
        "        \"justification_tokens\": out.get(\"justification_tokens\"),\n",
        "    })\n",
        "\n",
        "print(f\"Salvos {len(predictions)} resultados em {results_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Métricas e relatório"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.metrics import compute_metrics, save_metrics_report\n",
        "\n",
        "y_true = df_sample[label_col].astype(str).tolist()\n",
        "metrics = compute_metrics(y_true, predictions, labels=classes)\n",
        "save_metrics_report(metrics)\n",
        "\n",
        "print(\"Accuracy:\", metrics[\"accuracy\"])\n",
        "print(\"F1 macro:\", metrics[\"f1_macro\"])\n",
        "print(\"F1 weighted:\", metrics[\"f1_weighted\"])\n",
        "print(\"\\nClassification report:\")\n",
        "for k, v in metrics[\"classification_report\"].items():\n",
        "    if isinstance(v, dict):\n",
        "        print(k, v)\n",
        "    else:\n",
        "        print(k, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Exemplo de saída JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "ex = run_pipeline(compiled, texts[0], classes)\n",
        "print(json.dumps(ex, indent=2, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "ex = run_pipeline(compiled, texts[0], classes)\n",
        "print(json.dumps(ex, indent=2, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ticket-classifier",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
